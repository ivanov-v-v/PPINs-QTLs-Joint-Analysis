{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook the eQTL identification is performed.\n",
    "\n",
    "General workflow:\n",
    "- Extract two dataframes: marker-based genotype and expression data. Each column represents a strain. All columns are sorted accordingly to the strain name.\n",
    "- Transform them to matrices and perform MWU statistical test for every pair (marker, expressed gene) and save them into list. Use multiprocessing to speed the computation up.\n",
    "\t- For each marker, divide the strains by inherited variant.\n",
    "\t- For each gene, divide the expression data in two groups.\n",
    "\t- Test null hypothesis using MWU test.\n",
    "- Adjust the p-values using Benjamini-Hochberg procedure.\n",
    "- Construct the bipartite linkage graph using calculated q-values.\n",
    "- Plot the graph and the linkage map.\n",
    "\n",
    "TODO: \n",
    "- Прологарифмировать данные белковой экспрессии? — Это бесполезно, т.к. тест ранговый, а на монотонность логарифм не влияет.\n",
    "- Попытаться выяснить как можно больше про данные белковой экспрессии: \n",
    "\t- В столбцах со средними не средние арифметические. Что там за данные, насколько существенно отклонение? Нужно провести усреднение самостоятельно.\n",
    "\t- Гистрограмма p-values практически ровная.\n",
    "\t- Нормализация не сказывается на результате (да и без неё распределения довольно похожи на нормальное). + прочесть, для чего, в принципе, нужна нормализация, какие проблемы она решает, почему её нужно делать в моём случае. + прочесть о том, как были нормализованы данные экспрессии РНК и повторить аналогичную процедуру.\n",
    "\t- Даже без FDR-коррекции находятся не те linkages: это ОЧЕНЬ странно.\n",
    "\t- Та же функция корректно работает на данных экспрессии РНК.\n",
    "- Написать функцию, которая будет рисовать таблицу, где клетки будут окрашены в зависимости от унаследованного варианта, а в конце будут два столбца с центрамми масс облаков точек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 15 seconds\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy import stats\n",
    "import networkx as nx\n",
    "import multiprocessing as mp\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "from functools import partial\n",
    "\n",
    "%autosave 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expression data wasn't measured for all of the strains genotyped, \n",
    "# thereby some of them need to be filtered out beforehand\n",
    "genotype_df = pd.read_table('./data/genotypes.csv')\n",
    "\n",
    "rna_expression_df = pd.read_table('./data/rna_expression_avg.csv')\n",
    "rna_genotype_df = genotype_df[[\"RQTL_name\"] + rna_expression_df.columns.tolist()[1:]]\n",
    "pd.DataFrame.to_csv(rna_genotype_df, \"./data/rna_genotypes.csv\", sep='\\t', index=False)\n",
    "\n",
    "protein_expression_df = pd.read_table(\"./data/test_df.csv\")\n",
    "protein_genotype_df = genotype_df[[\"RQTL_name\"] + protein_expression_df.columns.tolist()[1:]]\n",
    "pd.DataFrame.to_csv(protein_genotype_df, \"./data/protein_genotypes.csv\", sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_p_values(genotype_matrix, expression_matrix, sample_pair):\n",
    "    markers_chunk, offset = sample_pair\n",
    "    p_values = np.zeros(len(markers_chunk) * expression_matrix.shape[0], dtype=np.float32)\n",
    "    iter = 0\n",
    "    for marker_rownum in range(offset, len(markers_chunk) + offset):\n",
    "        genotype_row = genotype_matrix[marker_rownum]\n",
    "        for expression_row in expression_matrix:\n",
    "            from_BY = expression_row[genotype_row == 0]\n",
    "            from_RM = expression_row[genotype_row == 1]\n",
    "            ''' CPU hog '''\n",
    "            statistics, p_value = stats.mannwhitneyu(x=from_BY, y=from_RM)\n",
    "            p_values[iter] = p_value\n",
    "            iter += 1\n",
    "    return p_values\n",
    "\n",
    "\n",
    "def perform_analysis(genotype_df, expression_df, analysis_name):\n",
    "    marker_cnt = genotype_df.shape[0]\n",
    "    \n",
    "    genotype_matrix = genotype_df.as_matrix(genotype_df.columns.tolist()[1:]) \n",
    "    expression_matrix = expression_df.as_matrix(expression_df.columns.tolist()[1:])\n",
    "    \n",
    "    expression_matrix = stats.zscore(\n",
    "        np.ma.array(\n",
    "            expression_matrix,\n",
    "            mask=np.isnan(expression_matrix)\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    \n",
    "    marker_list = genotype_df.iloc[:, 0].as_matrix()\n",
    "    gene_list = expression_df.iloc[:, 0].as_matrix()\n",
    "    \n",
    "    \n",
    "    CHUNKS_N = mp.cpu_count() // 2\n",
    "    marker_chunks = np.array_split(marker_list[:100], CHUNKS_N)\n",
    "    chunk_lens = np.roll(\n",
    "        np.cumsum(\n",
    "            [len(chunk) for chunk in marker_chunks]\n",
    "        ), 1\n",
    "    )\n",
    "    chunk_lens[0] = 0    \n",
    "    marker_samples = list(zip(marker_chunks, chunk_lens))\n",
    "\n",
    "    calculate_p_values_subroutine = partial(\n",
    "        calculate_p_values, \n",
    "        genotype_matrix, expression_matrix \n",
    "    )\n",
    "    \n",
    "    pool = mp.Pool(processes=CHUNKS_N)\n",
    "    start_time = time.time()\n",
    "    results = pool.map(calculate_p_values_subroutine, marker_samples)\n",
    "    end_time = time.time()\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    p_values = np.concatenate([results[i] for i in range(CHUNKS_N)])\n",
    "    # np.savetxt(analysis_name + \"_p_values.txt\", p_values, delimiter=',')\n",
    "    \n",
    "    adjusted_results = multipletests(p_values, method=\"fdr_bh\")\n",
    "    print(\"Calculation of pvalues: {}\".format(end_time - start_time))\n",
    "    \n",
    "    # Build linkage graph from qvalues\n",
    "    \n",
    "    reject, q_values = adjusted_results[0], adjusted_results[1]\n",
    "    linkage_graph = nx.Graph()\n",
    "    idx = 0\n",
    "    \n",
    "    for marker_name in marker_list[:100]:\n",
    "        for gene_name in gene_list:\n",
    "            if reject[idx] == True:\n",
    "                if not linkage_graph.has_node(gene_name):\n",
    "                    linkage_graph.add_node(gene_name, bipartite=0)\n",
    "                if not linkage_graph.has_node(marker_name):\n",
    "                    linkage_graph.add_node(marker_name, bipartite=1)\n",
    "                linkage_graph.add_edge(gene_name, marker_name)\n",
    "            idx += 1\n",
    "\n",
    "    # Built-in bipartite.sets() works strangely \n",
    "    # maybe, it's only so for undirected graphs,\n",
    "    # I should check that on some toy example\n",
    "\n",
    "    top_v, bottom_v = [], []\n",
    "    for node, data in linkage_graph.nodes(data=True):\n",
    "        if data[\"bipartite\"] == 0:\n",
    "            bottom_v.append(node)\n",
    "        else:\n",
    "            top_v.append(node)\n",
    "\n",
    "    if not linkage_graph.nodes():\n",
    "        print(\"No linkages found\")\n",
    "        return\n",
    "    \n",
    "    # Extract the marker-nodes and number of linkages to them\n",
    "    # preserving their order based on genome location\n",
    "\n",
    "    marker_to_rownum = dict(zip(genotype_df.iloc[:, 0], np.arange(marker_cnt)))\n",
    "    marker_nodes = sorted(\n",
    "        list(linkage_graph.degree(top_v).items()), \n",
    "        key=lambda p: marker_to_rownum[p[0]]\n",
    "    )\n",
    "\n",
    "    # Pythonic way of unzipping a list of tuples\n",
    "    # into two separate lists of their coordinates\n",
    "\n",
    "    marker_names, linkages = map(list, zip(*marker_nodes))  \n",
    "\n",
    "    plt.figure(figsize=(40, 20))\n",
    "    plt.plot(linkages)\n",
    "    plt.savefig(\"./img/\" + analysis_name + \"_linkage_map.png\")\n",
    "    plt.close()\n",
    "\n",
    "    graph_file = open(\"./data/\" + analysis_name + \"_linkage_graph.txt\", \"w+\")\n",
    "    for u in top_v:\n",
    "        graph_file.write(\"{}: {}\\n\".format(u, linkage_graph.degree(u)))\n",
    "        for v in linkage_graph[u]:\n",
    "            graph_file.write(\"{}\\n\".format(v))\n",
    "    graph_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation of pvalues: 76.19243812561035\n"
     ]
    }
   ],
   "source": [
    "perform_analysis(rna_genotype_df, rna_expression_df, \"eQTLs\")\n",
    "# perform_analysis(protein_genotype_df, protein_expression_df, \"pQTLs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "eQTL_df = pd.read_table(\n",
    "    \"eRESULTS.csv\",\n",
    "    sep='\\t'\n",
    ")\n",
    "\n",
    "linkage_graph = nx.Graph()\n",
    "for row in eQTL_df.itertuples():\n",
    "    marker_name, gene_name = row[1], row[2]\n",
    "    if not linkage_graph.has_node(gene_name):\n",
    "        linkage_graph.add_node(gene_name, bipartite=0)\n",
    "    if not linkage_graph.has_node(marker_name):\n",
    "        linkage_graph.add_node(marker_name, bipartite=1)\n",
    "    linkage_graph.add_edge(gene_name, marker_name)\n",
    "    \n",
    "top_v, bottom_v = [], []\n",
    "for node, data in linkage_graph.nodes(data=True):\n",
    "    if data[\"bipartite\"] == 0:\n",
    "        bottom_v.append(node)\n",
    "    else:\n",
    "        top_v.append(node)\n",
    "\n",
    "if not linkage_graph.nodes():\n",
    "    print(\"No linkages found\")\n",
    "\n",
    "    \n",
    "marker_to_rownum = dict(zip(\n",
    "    rna_genotype_df.iloc[:, 0], \n",
    "    np.arange(rna_genotype_df.shape[0])\n",
    "))\n",
    "\n",
    "marker_nodes = sorted(\n",
    "    list(linkage_graph.degree(top_v).items()), \n",
    "    key=lambda p: marker_to_rownum[p[0]]\n",
    ")\n",
    "\n",
    "marker_names, linkages = map(list, zip(*marker_nodes))  \n",
    "\n",
    "plt.figure(figsize=(40, 20))\n",
    "plt.plot(linkages)\n",
    "plt.savefig(\"./img/\" + \"MatrixQTL\" + \"_eQTL_linkage_map.png\")\n",
    "plt.close()\n",
    "\n",
    "# marker_nodes = sorted(\n",
    "#     list(linkage_graph.degree(top_v).items()), \n",
    "#     key=lambda p: marker_to_rownum[p[0]]\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "pQTL_df = pd.read_table(\n",
    "    \"pRESULTS.csv\",\n",
    "    sep='\\t'\n",
    ")\n",
    "\n",
    "linkage_graph = nx.Graph()\n",
    "for row in pQTL_df.itertuples():\n",
    "    marker_name, gene_name = row[1], row[2]\n",
    "    if not linkage_graph.has_node(gene_name):\n",
    "        linkage_graph.add_node(gene_name, bipartite=0)\n",
    "    if not linkage_graph.has_node(marker_name):\n",
    "        linkage_graph.add_node(marker_name, bipartite=1)\n",
    "    linkage_graph.add_edge(gene_name, marker_name)\n",
    "    \n",
    "top_v, bottom_v = [], []\n",
    "for node, data in linkage_graph.nodes(data=True):\n",
    "    if data[\"bipartite\"] == 0:\n",
    "        bottom_v.append(node)\n",
    "    else:\n",
    "        top_v.append(node)\n",
    "\n",
    "if not linkage_graph.nodes():\n",
    "    print(\"No linkages found\")\n",
    "\n",
    "    \n",
    "marker_to_rownum = dict(zip(\n",
    "    protein_genotype_df.iloc[:, 0], \n",
    "    np.arange(protein_genotype_df.shape[0])\n",
    "))\n",
    "\n",
    "marker_nodes = sorted(\n",
    "    list(linkage_graph.degree(top_v).items()), \n",
    "    key=lambda p: marker_to_rownum[p[0]]\n",
    ")\n",
    "\n",
    "marker_names, linkages = map(list, zip(*marker_nodes))  \n",
    "\n",
    "plt.figure(figsize=(40, 20))\n",
    "plt.plot(linkages)\n",
    "plt.savefig(\"./img/\" + \"MatrixQTL\" + \"_pQTL_linkage_map.png\")\n",
    "plt.close()\n",
    "\n",
    "# marker_nodes = sorted(\n",
    "#     list(linkage_graph.degree(top_v).items()), \n",
    "#     key=lambda p: marker_to_rownum[p[0]]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.to_csv(\n",
    "    rna_expression_df,\n",
    "    \"data/CPY_rna_expression_avg.csv\",\n",
    "    sep='\\t',\n",
    "    na_rep='NA',\n",
    "    index=False\n",
    ")\n",
    "pd.DataFrame.to_csv(\n",
    "    rna_genotype_df.replace([0, 1, 2], [0, 2, \"NA\"]),\n",
    "    \"data/CPY_rna_genotypes.csv\",\n",
    "    sep='\\t',\n",
    "    na_rep='NA',\n",
    "    index=False\n",
    ")\n",
    "pd.DataFrame.to_csv(\n",
    "    protein_expression_df,\n",
    "    \"data/CPY_protein_expression_avg.csv\",\n",
    "    sep='\\t',\n",
    "    na_rep='NA',\n",
    "    index=False\n",
    ")\n",
    "pd.DataFrame.to_csv(\n",
    "    protein_genotype_df.replace([0, 1, 2], [0, 2, \"NA\"]),\n",
    "    \"data/CPY_protein_genotypes.csv\",\n",
    "    sep='\\t',\n",
    "    na_rep='NA',\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_protein_df = pd.read_csv(\n",
    "    \"./data/Foss2007_protein_expression.csv\",\n",
    "    sep='\\t'\n",
    ")\n",
    "averaged_df = pd.DataFrame(\n",
    "    np.zeros((1318, 107)), \n",
    "    columns=protein_genotype_df.columns.tolist()[1:]\n",
    ")\n",
    "columns_grouped = dict(\n",
    "    [(strain_name, []) for strain_name in \n",
    "     protein_genotype_df.columns.tolist()[1:]\n",
    "    ]\n",
    ")\n",
    "for strain in raw_protein_df.columns.tolist():\n",
    "    tokenized = strain.split('.')\n",
    "    if tokenized[0] == 'cond' and tokenized[2] != 'median':\n",
    "            if tokenized[1] in columns_grouped.keys():\n",
    "                columns_grouped[tokenized[1]].append(strain)\n",
    "            \n",
    "for strain_name, group in columns_grouped.items():\n",
    "    subdf = raw_protein_df[group]\n",
    "    averaged_df[strain_name] = subdf.mean(axis=1)\n",
    "    \n",
    "# diff_df = protein_expression_df.iloc[:, 1:] - averaged_df\n",
    "averaged_df.insert(0, \"protein.group\", protein_expression_df[\"protein.group\"])\n",
    "    \n",
    "pd.DataFrame.to_csv(\n",
    "    averaged_df,\n",
    "    \"./data/test_df.csv\",\n",
    "    sep='\\t',\n",
    "    index=False,\n",
    "    na_rep='NA'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
