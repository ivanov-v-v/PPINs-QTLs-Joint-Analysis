{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook the eQTL identification is performed.\n",
    "\n",
    "General workflow:\n",
    "- Extract two dataframes: marker-based genotype and expression data. Each column represents a strain. All columns are sorted accordingly to the strain name.\n",
    "- Transform them to matrices and perform MWU statistical test for every pair (marker, expressed gene) and save them into list. Use multiprocessing to speed the computation up.\n",
    "\t- For each marker, divide the strains by inherited variant.\n",
    "\t- For each gene, divide the expression data in two groups.\n",
    "\t- Test null hypothesis using MWU test.\n",
    "- Adjust the p-values using Benjamini-Hochberg procedure.\n",
    "- Construct the bipartite linkage graph using calculated q-values.\n",
    "- Plot the graph and the linkage map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 15 seconds\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# utilities\n",
    "from functools import partial\n",
    "import time\n",
    "\n",
    "# data anal|ysis tools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "\n",
    "# network analysis tools\n",
    "import igraph\n",
    "import networkx as nx\n",
    "\n",
    "# multiprocessing tools\n",
    "import multiprocessing as mp\n",
    "\n",
    "# visualization tools\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "%autosave 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expression data wasn't measured for all of the strains genotyped, \n",
    "# thereby some of them need to be filtered out beforehand\n",
    "genotype_df = pd.read_table(\"./data/genotypes_full.csv\")\n",
    "\n",
    "\n",
    "rna_expression_df = pd.read_table(\"./data/rna_expression_avg.csv\")\n",
    "rna_genotype_df = pd.read_table(\"./data/rna_genotypes.csv\")\n",
    "\n",
    "protein_expression_df = pd.read_table(\"./data/protein_expression_avg.csv\")\n",
    "protein_genotype_df = pd.read_table(\"./data/protein_genotypes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_p_values(genotype_matrix, expression_matrix, sample_pair):\n",
    "    markers_chunk, offset = sample_pair\n",
    "    p_values = np.zeros(len(markers_chunk) * expression_matrix.shape[0], dtype=np.float32)\n",
    "    iter = 0\n",
    "    for marker_rownum in range(offset, len(markers_chunk) + offset):\n",
    "        genotype_row = genotype_matrix[marker_rownum]\n",
    "        for expression_row in expression_matrix:\n",
    "            from_BY = expression_row[genotype_row == 0]\n",
    "            from_RM = expression_row[genotype_row == 1]\n",
    "            ''' CPU hog '''\n",
    "            statistics, p_value = stats.mannwhitneyu(x=from_BY, y=from_RM)\n",
    "            p_values[iter] = p_value\n",
    "            iter += 1\n",
    "    return p_values\n",
    "\n",
    "# This way to identify QTLs is by orders of magnitude slower,\n",
    "# but provides a controllable environment, because I am fully aware\n",
    "# of all statistical procedures used in the analysis, unlike MatrixQTL\n",
    "def identify_QTLs(genotype_df, expression_df, analysis_name):\n",
    "    marker_cnt = genotype_df.shape[0]\n",
    "    \n",
    "    genotype_matrix = genotype_df.as_matrix(genotype_df.columns.tolist()[1:]) \n",
    "    expression_matrix = expression_df.as_matrix(expression_df.columns.tolist()[1:])\n",
    "    \n",
    "    expression_matrix = stats.zscore(\n",
    "        np.ma.array(\n",
    "            expression_matrix,\n",
    "            mask=np.isnan(expression_matrix)\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    \n",
    "    marker_list = genotype_df.iloc[:, 0].as_matrix()\n",
    "    gene_list = expression_df.iloc[:, 0].as_matrix()\n",
    "    \n",
    "    \n",
    "    CHUNKS_N = mp.cpu_count() // 2\n",
    "    marker_chunks = np.array_split(marker_list[:100], CHUNKS_N)\n",
    "    chunk_lens = np.roll(\n",
    "        np.cumsum(\n",
    "            [len(chunk) for chunk in marker_chunks]\n",
    "        ), 1\n",
    "    )\n",
    "    chunk_lens[0] = 0    \n",
    "    marker_samples = list(zip(marker_chunks, chunk_lens))\n",
    "\n",
    "    calculate_p_values_subroutine = partial(\n",
    "        calculate_p_values, \n",
    "        genotype_matrix, expression_matrix \n",
    "    )\n",
    "    \n",
    "    pool = mp.Pool(processes=CHUNKS_N)\n",
    "    start_time = time.time()\n",
    "    results = pool.map(calculate_p_values_subroutine, marker_samples)\n",
    "    end_time = time.time()\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    p_values = np.concatenate([results[i] for i in range(CHUNKS_N)])\n",
    "    \n",
    "    adjusted_results = multipletests(p_values, method=\"fdr_bh\")\n",
    "    print(\"Calculation of pvalues: {}\".format(end_time - start_time))\n",
    "    \n",
    "    # Build linkage graph from qvalues\n",
    "    \n",
    "    reject, q_values = adjusted_results[0], adjusted_results[1]\n",
    "    linkage_graph = nx.Graph()\n",
    "    idx = 0\n",
    "    \n",
    "    for marker_name in marker_list[:100]:\n",
    "        for gene_name in gene_list:\n",
    "            if reject[idx] == True:\n",
    "                if not linkage_graph.has_node(gene_name):\n",
    "                    linkage_graph.add_node(gene_name, bipartite=0)\n",
    "                if not linkage_graph.has_node(marker_name):\n",
    "                    linkage_graph.add_node(marker_name, bipartite=1)\n",
    "                linkage_graph.add_edge(gene_name, marker_name)\n",
    "            idx += 1\n",
    "\n",
    "    # Built-in bipartite.sets() works strangely \n",
    "    # maybe, it's only so for undirected graphs,\n",
    "    # I should check that on some toy example\n",
    "\n",
    "    top_v, bottom_v = [], []\n",
    "    for node, data in linkage_graph.nodes(data=True):\n",
    "        if data[\"bipartite\"] == 0:\n",
    "            bottom_v.append(node)\n",
    "        else:\n",
    "            top_v.append(node)\n",
    "\n",
    "    if not linkage_graph.nodes():\n",
    "        print(\"No linkages found\")\n",
    "        return\n",
    "    \n",
    "    # Extract the marker-nodes and number of linkages to them\n",
    "    # preserving their order based on genome location\n",
    "\n",
    "    marker_to_rownum = dict(zip(genotype_df.iloc[:, 0], np.arange(marker_cnt)))\n",
    "    marker_nodes = sorted(\n",
    "        list(linkage_graph.degree(top_v).items()), \n",
    "        key=lambda p: marker_to_rownum[p[0]]\n",
    "    )\n",
    "\n",
    "    # Pythonic way of unzipping a list of tuples\n",
    "    # into two separate lists of their coordinates\n",
    "\n",
    "    marker_names, linkages = map(list, zip(*marker_nodes))  \n",
    "\n",
    "    plt.figure(figsize=(40, 20))\n",
    "    plt.plot(linkages)\n",
    "    plt.savefig(\"./img/\" + analysis_name + \"_linkage_map.png\")\n",
    "    plt.close()\n",
    "\n",
    "    graph_file = open(\"./data/\" + analysis_name + \"_linkage_graph.txt\", \"w+\")\n",
    "    for u in top_v:\n",
    "        graph_file.write(\"{}: {}\\n\".format(u, linkage_graph.degree(u)))\n",
    "        for v in linkage_graph[u]:\n",
    "            graph_file.write(\"{}\\n\".format(v))\n",
    "    graph_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# identify_QTLs(rna_genotype_df, rna_expression_df, \"eQTLs\")\n",
    "# identify_QTLs(protein_genotype_df, protein_expression_df, \"pQTLs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assemble_QTLs_graph(QTLs_type, genotypes_df):\n",
    "    QTLs_df = pd.read_table(\n",
    "        \"./data/\" + QTLs_type + \".csv\",\n",
    "        sep='\\t'\n",
    "    )\n",
    "    \n",
    "    linkage_graph = nx.Graph()\n",
    "    for row in QTLs_df.itertuples():\n",
    "        marker_name, gene_name = row[1], row[2]\n",
    "        if not linkage_graph.has_node(gene_name):\n",
    "            linkage_graph.add_node(gene_name, bipartite=0)\n",
    "        if not linkage_graph.has_node(marker_name):\n",
    "            linkage_graph.add_node(marker_name, bipartite=1)\n",
    "        linkage_graph.add_edge(gene_name, marker_name)\n",
    "        \n",
    "    top_v, bottom_v = [], []\n",
    "    for node, data in linkage_graph.nodes(data=True):\n",
    "        if data[\"bipartite\"] == 0:\n",
    "            bottom_v.append(node)\n",
    "        else:\n",
    "            top_v.append(node)\n",
    "    \n",
    "    if not linkage_graph.nodes():\n",
    "        print(\"No linkages found\")\n",
    "    \n",
    "        \n",
    "    marker_to_rownum = dict(zip(\n",
    "        genotypes_df.iloc[:, 0], \n",
    "        np.arange(genotypes_df.shape[0])\n",
    "    ))\n",
    "    \n",
    "    marker_nodes = sorted(\n",
    "        list(linkage_graph.degree(top_v).items()), \n",
    "        key=lambda p: marker_to_rownum[p[0]]\n",
    "    )\n",
    "    \n",
    "    marker_names, linkages = map(list, zip(*marker_nodes))  \n",
    "    \n",
    "    nx.write_gexf(linkage_graph, \"./data/MatrixQTL_\" + QTLs_type + \"_linkage_graph.gexf\")\n",
    "    \n",
    "    plt.figure(figsize=(40, 20))\n",
    "    plt.plot(linkages)\n",
    "    plt.savefig(\"./img/MatrixQTL_\" + QTLs_type + \"_linkage_map.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    return linkage_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "eQTL_graph = assemble_QTLs_graph(\"eQTLs\", rna_genotype_df)\n",
    "pQTL_graph = assemble_QTLs_graph(\"pQTLs\", protein_genotype_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_interactome_df = pd.read_table(\"./data/yeast_interactome.csv\")\n",
    "eQTL_df = pd.read_table('./data/eQTLs.csv')\n",
    "pQTL_df = pd.read_table('./data/pQTLs.csv')\n",
    "\n",
    "eQTL_target_set = set(eQTL_df['gene']) \n",
    "pQTL_target_set = set(pQTL_df['gene'])\n",
    "\n",
    "interactome_df = full_interactome_df[\n",
    "    full_interactome_df['Interactor A'].isin(eQTL_target_set | pQTL_target_set)\n",
    "    & full_interactome_df['Interactor B'].isin(eQTL_target_set | pQTL_target_set)\n",
    "]\n",
    "\n",
    "interactome_df.set_index('Interaction Type', inplace=True)\n",
    "genetic_interaction_codes = [\n",
    "    'additive genetic interaction defined by inequality',\n",
    "    'suppressive genetic interaction defined by inequality',\n",
    "    'synthetic genetic interaction defined by inequality'\n",
    "]\n",
    "physical_interaction_codes = [\n",
    "    'association',\n",
    "    'colocalization',   \n",
    "    'direct interaction',\n",
    "    'physical association',\n",
    "]\n",
    "biogrid_mi_mapping_df = pd.read_table(\n",
    "    './data/biogrid_mi_mapping.csv'\n",
    ")\n",
    "genetic_interactions_df = interactome_df[\n",
    "    interactome_df.index.isin(genetic_interaction_codes)\n",
    "]\n",
    "physical_interactions_df = interactome_df[\n",
    "    interactome_df.index.isin(physical_interaction_codes)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assemble_interactions_graph(interaction_type, interacting_genes_df):\n",
    "    interactions_graph = nx.from_pandas_dataframe(\n",
    "        interacting_genes_df,\n",
    "        source='Interactor A',\n",
    "        target='Interactor B',\n",
    "        create_using=nx.MultiGraph()   \n",
    "    )\n",
    "    nx.write_gexf(interactions_graph, \"./data/interaction_graphs/\" + interaction_type + \"_interactions_graph.gexf\")\n",
    "    return interactions_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_graphs_dict = {}\n",
    "for interaction_type in set(interactome_df.index):\n",
    "    interacting_genes_df = interactome_df[interactome_df.index == interaction_type]\n",
    "    interactions_graphs_dict[interaction_type] = assemble_interactions_graph(interaction_type, interacting_genes_df)\n",
    "genetic_interactions_graph = assemble_interactions_graph('genetic', genetic_interactions_df)  \n",
    "physical_interactions_graph = assemble_interactions_graph('physical', physical_interactions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_interactome_df = pd.read_table(\n",
    "#     './data/BIOGRID-ORGANISM-Saccharomyces_cerevisiae_S288c-3.4.152.mitab.csv',\n",
    "#     usecols=['Alt IDs Interactor A', 'Alt IDs Interactor B', 'Interaction Types']\n",
    "# )\n",
    "# full_interactome_df['Alt IDs Interactor A'] = full_interactome_df['Alt IDs Interactor A'].apply(\n",
    "#     lambda s: s.split('|')[1].split(':')[1]\n",
    "# ) \n",
    "# full_interactome_df['Alt IDs Interactor B'] = full_interactome_df['Alt IDs Interactor B'].apply(\n",
    "#     lambda s: s.split('|')[1].split(':')[1]\n",
    "# ) \n",
    "# \n",
    "# full_interactome_df['Interaction Types'] = full_interactome_df['Interaction Types'].apply(\n",
    "#     lambda s: s.split('(')[1].split(')')[0]\n",
    "# ) \n",
    "# full_interactome_df.columns = [['Interactor A', 'Interactor B', 'Interaction Type']]\n",
    "# full_interactome_df.to_csv(\n",
    "#     './data/yeast_interactome.csv',\n",
    "#     index=False,\n",
    "#     sep='\\t'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genetic interactions, total: 3178 vertices, 188165 edges\n\tsynthetic genetic interaction defined by inequality: 2521 vertices, 16387 edges\n\tadditive genetic interaction defined by inequality: 3069 vertices, 139251 edges\n\tsuppressive genetic interaction defined by inequality: 3026 vertices, 32527 edges\nPhysical interactions, total: 3168 vertices, 56066 edges\n\tassociation: 1574 vertices, 2436 edges\n\tcolocalization: 595 vertices, 689 edges\n\tphysical association: 3030 vertices, 38521 edges\n\tdirect interaction: 2581 vertices, 14420 edges\n"
     ]
    }
   ],
   "source": [
    "print('Genetic interactions, total: {} vertices, {} edges'.format(\n",
    "    genetic_interactions_graph.number_of_nodes(),\n",
    "    genetic_interactions_graph.number_of_edges()\n",
    "))\n",
    "for name, graph in interactions_graphs_dict.items():\n",
    "    if name in genetic_interaction_codes:\n",
    "       print('\\t{}: {} vertices, {} edges'.format(\n",
    "            name,\n",
    "            graph.number_of_nodes(),\n",
    "            graph.number_of_edges()\n",
    "        ))\n",
    "print('Physical interactions, total: {} vertices, {} edges'.format(\n",
    "    physical_interactions_graph.number_of_nodes(),\n",
    "    physical_interactions_graph.number_of_edges()\n",
    "))\n",
    "for name, graph in interactions_graphs_dict.items():\n",
    "    if name in physical_interaction_codes:\n",
    "       print('\\t{}: {} vertices, {} edges'.format(\n",
    "            name,\n",
    "            graph.number_of_nodes(),\n",
    "            graph.number_of_edges()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
